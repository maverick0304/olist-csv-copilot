# Olist Copilot ğŸ›’

A production-ready GenAI agentic system for natural-language analytics. Ask questions in **any language**, get SQL-powered insights with auto-generated charts.

## ğŸ¬ Walkthrough

Video link: 

```
https://drive.google.com/drive/folders/1K3GFHg33HvE-udz3jVCpZYD67yr9skao?usp=sharing
```

## âœ¨ Features

### Core Capabilities
- ğŸ—£ï¸ **Natural Language Q&A** - "What were the top 5 categories by revenue in 2018?"
- ğŸ¤– **Autonomous Agent** - Plans â†’ Generates SQL â†’ Executes â†’ Visualizes
- ğŸ“Š **Smart Visualizations** - Auto-generated charts based on query type
- ğŸ’¾ **Session Memory** - Follow-ups remember context
- ğŸ”’ **Safe Execution** - Read-only SQL with strict validation
- ğŸ“¥ **Export Ready** - Download results as CSV

### Advanced Features
- ğŸŒ **Multilingual** - Ask in English, Portuguese, Hindi, Spanish, French, Arabic, Chinese, Japanese, Korean, etc.
- ğŸ“š **Semantic Layer** - Pre-defined business metrics (GMV, AOV, repeat rate)
- ğŸ§  **RAG-Enhanced** - Retrieves schema and past queries for better accuracy
- ğŸ’¡ **Contextual Suggestions** - AI-powered follow-up questions
- ğŸ“‚ **Custom CSV Mode** - Upload your own data and ask questions instantly

### Two Modes

**1. Olist Mode** (Default)
- Analyze Brazilian e-commerce dataset
- Pre-configured schema and metrics
- Optimized for retail analytics

**2. CSV Mode** 
- Upload any CSV files
- Auto-detects schema and relationships
- Generates custom prompts dynamically

---

## ğŸš€ Quick Start

### Prerequisites
- Python 3.10+
- Google Gemini API Key ([Free](https://makersuite.google.com/app/apikey)) or Groq API Key ([Free](https://console.groq.com))

### Installation

```bash
# 1. Clone and install dependencies
git clone https://github.com/yourusername/olist-copilot.git
cd olist-copilot
pip install -r requirements.txt

# 2. Configure API keys
# Edit .env and add:
#   GEMINI_API_KEY=your_key_here
#   OR
#   GROQ_API_KEY=your_key_here

# 3. Download Olist dataset (for Olist mode)
# Option A: Manual from Kaggle
https://www.kaggle.com/datasets/olistbr/brazilian-ecommerce/
# Extract all CSVs to data/raw/

# Option B: Kaggle CLI
pip install kaggle
kaggle datasets download -d olistbr/brazilian-ecommerce
unzip brazilian-ecommerce.zip -d data/raw/

# 4. Build database (for Olist mode)
python scripts/build_duckdb.py

# 5. Launch!
streamlit run app/main.py
```

Open http://localhost:8501 ğŸ‰

---



---

## ğŸ’¬ Example Questions

### Olist Mode
```
"What are the top 5 product categories by GMV in 2018?"
"Show me monthly revenue trends for Electronics"
"Which sellers have the worst on-time delivery rate?"
"Compare payment methods by transaction value"
"What's the customer repeat purchase rate?"
```

### CSV Mode
```
"How many unique cities are there?"
"What are the top 10 products by sales?"
"Show me monthly sales trends"
"Which customers spent the most?"
```

### Multilingual
```
"Mostre-me as vendas totais por categoria" (Portuguese)
"à¤®à¥à¤à¥‡ à¤¶à¥à¤°à¥‡à¤£à¥€ à¤•à¥‡ à¤…à¤¨à¥à¤¸à¤¾à¤° à¤¬à¤¿à¤•à¥à¤°à¥€ à¤¦à¤¿à¤–à¤¾à¤à¤‚" (Hindi)
"MuÃ©strame las ventas por categorÃ­a" (Spanish)
```

---

## ğŸ“‚ Project Structure

```
olist-copilot/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main.py                 # Main Streamlit UI (Olist mode)
â”‚   â”œâ”€â”€ agent.py                # Core agent orchestration
â”‚   â”œâ”€â”€ pages/
â”‚   â”‚   â””â”€â”€ csv_mode.py         # CSV upload & analysis UI
â”‚   â”œâ”€â”€ tools/
â”‚   â”‚   â”œâ”€â”€ sql_tool.py         # SQL execution (DuckDB)
â”‚   â”‚   â”œâ”€â”€ viz_tool.py         # Chart generation (Plotly)
â”‚   â”‚   â”œâ”€â”€ glossary_tool.py    # Semantic metrics
â”‚   â”‚   â”œâ”€â”€ rag_tool.py         # RAG for schema retrieval
â”‚   â”‚   â”œâ”€â”€ csv_tool.py         # CSV analysis & profiling
â”‚   â”‚   â”œâ”€â”€ data_profiler.py    # Data quality checks
â”‚   â”‚   â””â”€â”€ translate_tool.py   # Language detection
â”‚   â”œâ”€â”€ llm/
â”‚   â”‚   â””â”€â”€ provider.py         # LLM abstraction (Gemini/Groq/Ollama/HF)
â”‚   â”œâ”€â”€ prompts/
â”‚   â”‚   â”œâ”€â”€ system.txt          # Legacy prompt
â”‚   â”‚   â”œâ”€â”€ sql_generation_v2.txt  # Enhanced SQL prompt
â”‚   â”‚   â”œâ”€â”€ context_wrapper.txt    # Domain context layer
â”‚   â”‚   â”œâ”€â”€ complete_schema.txt    # Detailed schema docs
â”‚   â”‚   â”œâ”€â”€ few_shots.json         # Example queries (Olist)
â”‚   â”‚   â””â”€â”€ csv_prompt_generator.py # Dynamic prompts (CSV mode)
â”‚   â”œâ”€â”€ semantic/
â”‚   â”‚   â”œâ”€â”€ metrics.yaml        # Business metric definitions
â”‚   â”‚   â””â”€â”€ schema.md           # Auto-generated schema reference
â”‚   â””â”€â”€ memory/
â”‚       â””â”€â”€ sessions.sqlite     # Session storage
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                    # Kaggle CSVs (user provides)
â”‚   â”œâ”€â”€ duckdb/
â”‚   â”‚   â””â”€â”€ olist.duckdb        # Built database
â”‚   â””â”€â”€ README.md
â”œâ”€â”€ test_data/                  # Sample CSVs for testing
â”‚   â”œâ”€â”€ customers.csv
â”‚   â”œâ”€â”€ sales.csv
â”‚   â””â”€â”€ products.csv
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ build_duckdb.py         # Data ingestion pipeline
â”‚   â””â”€â”€ profile_schema.py       # Schema doc generator
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ test_sql_generation.py  # SQL safety tests
â”œâ”€â”€ .env.example                # Environment template
â”œâ”€â”€ requirements.txt            # Dependencies
â”œâ”€â”€ README.md                   # This file
â””â”€â”€ ARCHITECTURE.md             # Technical docs
```

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚        Streamlit UI                      â”‚
â”‚  [Chat] [Charts] [CSV Export]            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           Agent (agent.py)               â”‚
â”‚  Plan â†’ Generate SQL â†’ Execute â†’ Insight â”‚
â”‚                                           â”‚
â”‚  Powered by: Gemini / Groq / Ollama      â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚      â”‚        â”‚      â”‚
  â”Œâ”€â”€â”€â”€â–¼â”€â”€â” â”Œâ–¼â”€â”€â”€â”€â” â”Œâ”€â–¼â”€â”€â” â”Œâ–¼â”€â”€â”€â”€â”€â”
  â”‚SQL    â”‚ â”‚Viz  â”‚ â”‚RAG â”‚ â”‚Gloss.â”‚
  â”‚Tool   â”‚ â”‚Tool â”‚ â”‚Toolâ”‚ â”‚Tool  â”‚
  â””â”€â”€â”€â”¬â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”˜
      â”‚
  â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚  DuckDB Database   â”‚
  â”‚  or In-Memory CSV  â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

For detailed architecture, see [ARCHITECTURE.md](ARCHITECTURE.md).

---

## ğŸ”’ Security & Guardrails

âœ… **Read-Only Database** - DuckDB opened in read-only mode  
âœ… **SQL Validation** - Only SELECT statements allowed  
âœ… **Table Whitelist** - Only pre-defined tables accessible  
âœ… **No Secrets in Code** - All keys from .env  
âœ… **Auto-Repair** - Self-corrects common SQL errors

**Forbidden:**
- DDL (CREATE, ALTER, DROP)
- DML (INSERT, UPDATE, DELETE)
- System commands (PRAGMA, ATTACH)
- SQL injection patterns

---

## ğŸŒ Multilingual Support

**Supported Languages:**
- English
- Portuguese (Brazilian)
- Spanish
- Hindi
- French
- German
- Chinese (Simplified)
- Japanese
- Korean
- Arabic
- And 45+ more via auto-detection

**How it works:**
1. User asks in any language
2. `langdetect` identifies language with confidence check
3. LLM generates SQL (universal)
4. LLM generates insight in user's language
5. Follow-up questions also in user's language

**No configuration needed** - just ask naturally!

---

## ğŸ¤– LLM Providers

### Supported Models

**1. Google Gemini (Default)**
- Free tier: 15 requests/minute
- Model: `gemini-2.5-flash`
- Best for: General queries

**2. Groq (Fastest)**
- Free tier: 30 requests/minute
- Model: `llama-3.3-70b-versatile`
- Best for: Speed (10x faster than Gemini)

**3. Ollama (Local)**
- Models: `llama3.2`, `codellama`, `mistral`, `phi3`
- Best for: Privacy, no API costs

**4. HuggingFace (Free)**
- Models: Various open-source
- Best for: Experimentation

### Switch Providers

Edit `app/llm/provider.py`:
```python
# Use Groq (fast, free)
from app.llm.provider import GroqProvider
llm = GroqProvider(api_key=os.getenv("GROQ_API_KEY"))

# Use Ollama (local)
from app.llm.provider import OllamaProvider
llm = OllamaProvider(model="llama3.2")
```

---

## ğŸ“Š Semantic Metrics

Pre-defined business metrics with SQL templates:

| Metric | Description | Formula |
|--------|-------------|---------|
| **GMV** | Gross Merchandise Value | SUM(order_value) |
| **AOV** | Average Order Value | AVG(order_value) |
| **Repeat Rate** | % returning customers | customers_with_2+_orders / total_customers |
| **On-Time Delivery** | % delivered by estimate | delivered_on_time / total_delivered |
| **Category Penetration** | % buying from category | customers_in_category / total_customers |

Access via: `"Explain GMV"` or `"What metrics are available?"`

---

## ğŸ§ª Testing

```bash
# Run all tests
pytest

# With coverage
pytest --cov=app --cov-report=html

# SQL validation tests
pytest tests/test_sql_generation.py -v

# Test CSV mode
python test_csv_mode.py
```

---

## â–¶ï¸ Run the App Anytime

Once dependencies are installed and your `.env` is configured, launch the Streamlit experience with:

```bash
streamlit run app/main.py
```

The UI will open at [http://localhost:8501](http://localhost:8501).

---

## ğŸ› Troubleshooting

### Import Errors
```bash
pip install -r requirements.txt
```

### Database Not Found
```bash
python scripts/build_duckdb.py
```

### API Key Errors
- Ensure `.env` file exists
- Check key is valid at provider website
- Verify key name: `GEMINI_API_KEY` or `GROQ_API_KEY`

### Empty Results
- Check date range filters
- Verify CSV files in `data/raw/`
- Rebuild database

### Language Detection Issues
- Short queries (<15 chars) default to English
- Non-English requires >80% confidence
- Override by being more explicit in your query

---

## ğŸš€ Future Enhancements

If I had more time, here's what I would add:

- **Vector Search** - Embed schema descriptions for semantic column matching
- **Multi-Modal Charts** - Scatter plots, heatmaps, geographic visualizations
- **Query History & Bookmarks** - Save favorite queries and share with team
- **Scheduled Reports** - Recurring analytics with email/Slack delivery
- **Real-Time Data Pipeline** - Streaming ingestion for live dashboards
- **Multi-User Authentication** - Role-based access and query audit logs
- **Advanced Anomaly Detection** - Statistical outlier detection in time series
- **Natural Language Explanations** - LLM-generated insights on trends and patterns

---

## ğŸ™ Acknowledgments

- **Dataset:** [Olist Brazilian E-commerce](https://www.kaggle.com/datasets/olistbr/brazilian-ecommerce/)
- **Built with:** Streamlit, DuckDB, Google Gemini, Groq, Plotly
- **Inspired by:** Modern AI agent architectures

---

Built with â¤ï¸ for production-ready AI agents
